{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06fe1fb",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "\n",
    "This document discusses a simple sentence generator program, which mimicks real life language models, as well as details regarding how the algorithm functions. \n",
    "\n",
    "This program functions by recieving a list of sentences, and is able to output new sentences with a given starting word.\n",
    "\n",
    "\n",
    "If you are too impatient to reading the whole document, here are some outputs generated by this program:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a06a9",
   "metadata": {},
   "source": [
    "Note:\n",
    "Please keep in mind that this project does not use actual machine learning elements, rather it was merely inspired by the general idea. More information and limitations of the program can be found in the end of the documentation.\n",
    "\n",
    "Note 2:\n",
    "Since this is a Jupyter notebook, you should be able to execute these programs directly in this document, provided that you downloaded it and have properly set up Python. However, you need to run the function declarations first before you can run the provided examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d36a2",
   "metadata": {},
   "source": [
    "Section 1: Interpretation\n",
    "\n",
    "This section discusses how the program reads in info, and how it processes said inputs for \"learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26f375a-e123-408a-aa1e-75d3d1e2090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function breaks down sentences into digestable chunks for the program to analyze\n",
    "\n",
    "PUNCTS = (\".\", \"?\", \"!\") #Given list of currently accepted punctuations\n",
    "\n",
    "def processSentence(sentence):\n",
    "    chunks = []\n",
    "    nextChunk = \"\"\n",
    "\n",
    "    for i in sentence:\n",
    "        if i in PUNCTS:\n",
    "            chunks.append(nextChunk)\n",
    "            nextChunk = \"\"\n",
    "\n",
    "            chunks.append(i)\n",
    "        elif i == \" \":\n",
    "            if len(nextChunk) > 0:\n",
    "                chunks.append(nextChunk)\n",
    "                nextChunk = \"\"\n",
    "        else:\n",
    "            nextChunk += i\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d704f4",
   "metadata": {},
   "source": [
    "Below is an example of the executed program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f10ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "print(processSentence(sentence))\n",
    "#['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18852b10",
   "metadata": {},
   "source": [
    "Section 2: Training\n",
    "\n",
    "This section discusses how the program conform itself to the processed input, in preparation for sentence generating. This is the second level of preprocessing before the program can actually create its own outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4fb49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedMatrix = {\n",
    "    #\"SampleWord\" : [[NextWords], [NextProbs]]\n",
    "}\n",
    "\n",
    "def train(trainingSentences, targetMatrix):\n",
    "    for sen in trainingSentences:\n",
    "        procSen = processSentence(sen)\n",
    "\n",
    "        for i in range(len(procSen)):\n",
    "            chk = procSen[i]\n",
    "            prevChk = procSen[i-1] if i > 0 else None\n",
    "\n",
    "\n",
    "            if not chk in PUNCTS and not chk in targetMatrix.keys():\n",
    "                targetMatrix[chk] = [[], []]\n",
    "            \n",
    "            if prevChk is not None:\n",
    "\n",
    "                if chk in targetMatrix[prevChk][0]:\n",
    "                    updatedWrdList = targetMatrix[prevChk][0]\n",
    "                    updatedProbList = targetMatrix[prevChk][1]\n",
    "\n",
    "                    chkIndex = updatedWrdList.index(chk)\n",
    "                    updatedProbList[chkIndex] += 1\n",
    "\n",
    "                    targetMatrix.update({prevChk : [updatedWrdList, updatedProbList]})\n",
    "                else:\n",
    "                    updatedWrdList = targetMatrix[prevChk][0]\n",
    "                    updatedProbList = targetMatrix[prevChk][1]\n",
    "\n",
    "                    updatedWrdList.append(chk)\n",
    "                    updatedProbList.append(1)\n",
    "\n",
    "                    targetMatrix.update({prevChk : [updatedWrdList, updatedProbList]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0eab2",
   "metadata": {},
   "source": [
    "Below is an example of the executed program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0d47c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [['b', 'c'], [1, 1]], 'b': [['.', 'c'], [1, 1]], 'c': [['.'], [2]]}\n"
     ]
    }
   ],
   "source": [
    "#Training sentences, each letter represents a word\n",
    "testSentences = (\n",
    "    \"a b.\",\n",
    "    \"b c.\",\n",
    "    \"a c.\"\n",
    ")\n",
    "\n",
    "trainedMatrix = {\n",
    "    #\"SampleWord\" : [[NextWords], [NextProbs]]\n",
    "}\n",
    "\n",
    "train(testSentences, trainedMatrix)\n",
    "\n",
    "print(trainedMatrix)\n",
    "#{'a': [['b', 'c'], [1, 1]], 'b': [['.', 'c'], [1, 1]], 'c': [['.'], [2]]}\n",
    "\n",
    "#Here is a more visual representation of the created Markov Chain:\n",
    "#   a b c .\n",
    "# a 0 1 1 0 (both 'b' and 'c' appeared once after 'a' in all of the sentences)\n",
    "# b 0 0 1 1\n",
    "# c 0 0 0 2 (Note that the period appeared after 'c' twice, hence the 2 here)\n",
    "# . - - - - (ending punctuations are a special case, as the program terminates everytime these symbols were generated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dceee8",
   "metadata": {},
   "source": [
    "Section 3: Generation\n",
    "\n",
    "This section touches on how the program uses all the preprocessed data to actually create its outputs.\n",
    "\n",
    "The fundamental idea of most large problems are to divide it into smaller, more approachable tasks. Language models are no exception to this. As such, before considering how to generate a sentence, it may be helpful to consider how to generate the next word.\n",
    "\n",
    "With the given processed data from the previous sections, we now know what words could be next, as well as their frequencies in the original training data. Therefore, our program can use this to its advantage to choose a random possible word, with the probability being decided by the frequencies of appearance.\n",
    "\n",
    "Imagine a simple number range from 0 to 1. We can divide this range into different, smaller chunks of various sizes (for example: 0.5, 0.3, and 0.2). If we generate a random number between 0 and 1, this number would be in one of these chunks. Larger sized chunks means a higher chance that the random number would fall into its range. If we take this concept and map each chunk to a corresponding word, we have now created a simple way of picking a random word with varied probabilities.\n",
    "\n",
    "Below are the two functions responsible for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e298d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#These functions create scaled chunks based on the given information, and then select a random chunk, see more in the documentation\n",
    "\n",
    "#Helper function, this confines the probability range between 0 and 1\n",
    "def probabilityGradient(probs):\n",
    "    total = sum(probs)\n",
    "    return [i/total for i in probs]\n",
    "\n",
    "#This function returns the index of the randomly chosen section\n",
    "def selectValue(probs):\n",
    "    gradient = probabilityGradient(probs)\n",
    "    target = random.random()\n",
    "    total = 0\n",
    "    result = 0\n",
    "\n",
    "    for bound in gradient:\n",
    "        total += bound\n",
    "\n",
    "        if target <= total:\n",
    "            return result\n",
    "        result += 1\n",
    "\n",
    "    #technically it would never reach this point but just return the last chunk in case it didn't pick anything prior\n",
    "    return len(gradient) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5a77f",
   "metadata": {},
   "source": [
    "After being able to predict the next word, now the program can simply generate a full sentence through recursion, using its previous output as the next input.\n",
    "\n",
    "In the case that the previous word has never be encountered before (if it was not part of the training data), the program would simply return an error. More information are in the documentation below regarding domains and limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed1d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LIM = 50 #Hard stop maximum sentence length to prevent possible infinite recursion\n",
    "\n",
    "def generate(startWrd, matrix):\n",
    "    sent = [startWrd]\n",
    "\n",
    "    if not startWrd in matrix.keys():\n",
    "        print(\"Starting word hasn't been learnt before\")\n",
    "        return None\n",
    "\n",
    "    def generateRec(prevWrd):\n",
    "        if len(sent) >= MAX_SENT_LIM:\n",
    "            return False\n",
    "        else:\n",
    "            nxtWords = matrix[prevWrd][0]\n",
    "            nextProbs = matrix[prevWrd][1]\n",
    "\n",
    "            nxtWord = nxtWords[selectValue(nextProbs)]\n",
    "            sent.append(nxtWord)\n",
    "\n",
    "            if nxtWord in PUNCTS:\n",
    "                return True\n",
    "            else:\n",
    "                return generateRec(nxtWord)\n",
    "\n",
    "    outcome = generateRec(startWrd)\n",
    "\n",
    "    if outcome:\n",
    "        print(\"Success, returning current result\")\n",
    "        return(sent)\n",
    "    else:\n",
    "        print(\"Exceeded maximum word limit, returning current result\")\n",
    "        return(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e58754",
   "metadata": {},
   "source": [
    "Section 4: Results\n",
    "\n",
    "This section provides example input and outputs of the program, while giving a deeper analysis on said inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c522ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success, returning current result\n",
      "['They', 'built', 'a', 'snowman', 'in', 'my', 'free', 'time', '.']\n"
     ]
    }
   ],
   "source": [
    "MAX_SENT_LIM = 50\n",
    "PUNCTS = (\".\", \"?\", \"!\")\n",
    "\n",
    "TRAIN_SENT = ( #generously provided by ChatGPT 3.5\n",
    "    \"The cat is sleeping on the mat.\",\n",
    "    \"I enjoy reading books in my free time.\",\n",
    "    \"She greeted me with a warm smile.\",\n",
    "    \"The students are studying for their exams.\",\n",
    "    \"They went for a walk in the park.\",\n",
    "    \"The flowers in the garden are blooming beautifully.\",\n",
    "    \"She is wearing a red dress to the party.\",\n",
    "    \"They built a sandcastle on the beach.\",\n",
    "    \"We visited the museum to see the art exhibition.\",\n",
    "    \"The baby giggled at the funny sounds.\",\n",
    "    \"He fixed the broken chair with a hammer.\",\n",
    "    \"The birds are chirping in the trees.\",\n",
    "    \"She danced gracefully on the stage.\",\n",
    "    \"He painted a beautiful landscape on the canvas.\",\n",
    "    \"The rain is pouring heavily outside.\",\n",
    "    \"She gave a speech at the conference.\",\n",
    "    \"He won a gold medal in the swimming competition.\",\n",
    "    \"The children played happily in the playground.\",\n",
    "    \"They built a snowman in the backyard.\",\n",
    "    \"We took a family photo during the vacation.\",\n",
    "    \"I solved the puzzle in record time.\",\n",
    "    \"They went on a road trip across the country.\",\n",
    "    \"We attended a music concert in the city.\",\n",
    "    \"I practiced playing the piano every day.\",\n",
    "    \"They enjoyed a sunset cruise on the lake.\",\n",
    "    \"We volunteered at a local charity event.\"\n",
    ")\n",
    "\n",
    "#Actual code, run all of the function declarations in the previous function for this part to work.\n",
    "train(TRAIN_SENT, trainedMatrix)\n",
    "\n",
    "#Select a random valid starting word, taken from the training sentences\n",
    "START_WORDS = (\"I\", \"He\", \"She\", \"They\", \"The\")\n",
    "startWrd = START_WORDS[int(random.random() * len(START_WORDS))]\n",
    "\n",
    "#This will provide a random result, have fun\n",
    "print(generate(startWrd, trainedMatrix))\n",
    "\n",
    "#The result is a list of the words, the official version of the program provides a helper function that turns it back into one string, but it is not included here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6209e69",
   "metadata": {},
   "source": [
    "#Section 5: Implications and Limitations\n",
    "\n",
    "This section discusses more about the general idea as well as possible future features that can greatly improve this very basic program.\n",
    "\n",
    "*1: Domain of Input Sentences*\n",
    "\n",
    "Currently, this program only accept very simple sentences, with only one independent clause. There is also a small given list of accepted ending punctuations (period, question mark, exclamation mark), and no commas are currently accepted as part of a valid training sentence. Despite this, the basis of multi-clause sentences are already avaliable, and may be updated in the near future.\n",
    "\n",
    "*2: Sentence \"Comprehension\"*\n",
    "\n",
    "It is obvious that this program generates rather nonsensical outputs, due to the recursive method only considering the previous word only. Larger, more advanced language models takes into account much more prior information.\n",
    "\n",
    "*3: Word Choice*\n",
    "\n",
    "Due to resource and personal limitations, this program simply picks words based on pure randomness, and the probability is only affected by appearance frequencies. In addition, if the training sentences are too unique from one another (sharing little words in common), there would be less opportunities for the program to creatively branch off. As such it'll just create one of the original training sentences, which is unfortunate and boring.\n",
    "\n",
    "However theoretically, it may be possible to adjust and skew the probabilities using concepts from linear algebra. For example, a word can be weighted more heavily from another word to favor the former in generation. This can be achieved through matrix multiplications, and could be incredibly useful to control the feel of the result, such as making it sound more positive or negative in general. Unfortunately, more development into biases and weights would be needed for the generation of a more nuanced and clear narrative, and I'm not sure if I have the time or knowledge to pull it off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba716a5",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "Overall, although this program obviously have little practical purposes (due to its limitations as well as being unable to compete with real language models), it may act as an oversimplified example for curious beginners who are looking into the field of artificial intelligence. At least, I had a fun time making this, and I hope that this document has been entertaining to read as well as being somewhat educational and insightful.\n",
    "\n",
    "Thank you for reading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
